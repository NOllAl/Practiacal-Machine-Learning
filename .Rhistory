data$Activity <- factor(data$Activity,level=1:6,labels=c("Walk","Walk_Up","Walk_Down","Sit","Stand","Lay"))
varnames <- readLines(paste(curdir,"/data/UCI HAR Dataset/features.txt",sep="")) #Get variable names
ind <- grep("mean\\(|std",varnames) + 2    #get indices containing mean and sd measurement (and add one, because we added the activity and subject column)
ind <- c(1,2, ind)                #add activity label
data <- data1[,ind]             #select data measurement with mean and standard variables
#Change variable names to something descriptive
varnames <- varnames[ind-2]
varnames <- (gsub("[0-9]+ ","",varnames))  #get rid of numbers in front
#varnames <- gsub("-mean\\(\\)","Mean",varnames) #get rid of dash and () in mean
#varnames <- gsub("-std\\(\\)","Std",varnames)
varnames <- c("Activity","Subject",varnames)
names(data) <- varnames
data$Activity <- factor(data$Activity,level=1:6,labels=c("Walk","Walk_Up","Walk_Down","Sit","Stand","Lay"))
#Change variable names to something descriptive
varnames <- varnames[ind[3:length(ind)]]
varnames <- (gsub("[0-9]+ ","",varnames))  #get rid of numbers in front
#varnames <- gsub("-mean\\(\\)","Mean",varnames) #get rid of dash and () in mean
#varnames <- gsub("-std\\(\\)","Std",varnames)
varnames <- c("Activity","Subject",varnames)
names(data) <- varnames
data$Activity <- factor(data$Activity,level=1:6,labels=c("Walk","Walk_Up","Walk_Down","Sit","Stand","Lay"))
View(data)
#Create the seconde data second required in the assignment
data_sum <- aggregate(data[,3:dim(data)[2]],by=list(Acttivity=data$Activity),mean)
View(data_sum)
View(data)
#Create the seconde data second required in the assignment
data_sum <- aggregate(data[,3:dim(data)[2]],by=list(Acttivity=data$Activity,subject=data$Subject),mean)
View(data_sum)
#Write mean data to txt file
write.table(data_sum,file="data_sum.txt",row.name=FALSE)
#Download and unzip data
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
if (!file.exists("data")){dir.create("data")}
curdir <- getwd()
setwd(paste(curdir,"/data/",sep=""))
download.file(url,destfile="data.zip")
unzip("data.zip")
setwd(curdir)
#Load data and merge training with test data
test_data <- read.table(paste(curdir,"/data/UCI HAR Dataset/test/X_test.txt",sep=""))
test_data_act <- read.table(paste(curdir,"/data/UCI HAR Dataset/test/Y_test.txt",sep=""))
test_data_sub <- read.table(paste(curdir,"/data/UCI HAR Dataset/test/subject_test.txt",sep=""))
test_data <- cbind(test_data_act,test_data_sub,test_data)
train_data <- read.table(paste(curdir,"/data/UCI HAR Dataset/train/X_train.txt",sep=""))
train_data_act <- read.table(paste(curdir,"/data/UCI HAR Dataset/train/Y_train.txt",sep=""))
train_data_sub <- read.table(paste(curdir,"/data/UCI HAR Dataset/train/subject_train.txt",sep=""))
train_data <- cbind(train_data_act,train_data_sub,train_data)
data1 <- rbind(test_data,train_data)
varnames <- readLines(paste(curdir,"/data/UCI HAR Dataset/features.txt",sep="")) #Get variable names
ind <- grep("mean\\(|std",varnames)     #get indices containing mean and sd measurement (and add one, because we added the activity and subject column)
ind <- c(1,2, ind+2)                #add activity label
data <- data1[,ind]             #select data measurement with mean and standard variables
#Change variable names to something descriptive
varnames <- varnames[ind[3:length(ind)]]
varnames <- (gsub("[0-9]+ ","",varnames))  #get rid of numbers in front
varnames <- gsub("-mean\\(\\)","Mean",varnames) #get rid of dash and () in mean
varnames <- gsub("-std\\(\\)","Std",varnames)
varnames <- c("Activity","Subject",varnames)
names(data) <- varnames
data$Activity <- factor(data$Activity,level=1:6,labels=c("Walk","Walk_Up","Walk_Down","Sit","Stand","Lay"))
#Create the seconde data second required in the assignment
data_sum <- aggregate(data[,3:dim(data)[2]],by=list(Acttivity=data$Activity,subject=data$Subject),mean)
#Write mean data to txt file
write.table(data_sum,file="data_sum.txt",row.name=FALSE)
View(data_sum)
View(data_sum)
View(data1)
View(data_sum)
View(data_sum)
#Change variable names to something descriptive
varnames <- varnames[ind[3:length(ind)]-2]
varnames <- (gsub("[0-9]+ ","",varnames))  #get rid of numbers in front
varnames <- gsub("-mean\\(\\)","Mean",varnames) #get rid of dash and () in mean
varnames <- gsub("-std\\(\\)","Std",varnames)
varnames <- c("Activity","Subject",varnames)
names(data) <- varnames
data$Activity <- factor(data$Activity,level=1:6,labels=c("Walk","Walk_Up","Walk_Down","Sit","Stand","Lay"))
#Create the seconde data second required in the assignment
data_sum <- aggregate(data[,3:dim(data)[2]],by=list(Acttivity=data$Activity,subject=data$Subject),mean)
#Write mean data to txt file
write.table(data_sum,file="data_sum.txt",row.name=FALSE)
View(data_sum)
varnames <- varnames[ind[3:length(ind)]-2]
varnames <- readLines(paste(curdir,"/data/UCI HAR Dataset/features.txt",sep="")) #Get variable names
ind <- grep("mean\\(|std",varnames)     #get indices containing mean and sd measurement (and add one, because we added the activity and subject column)
ind <- c(1,2, ind+2)                #add activity label
data <- data1[,ind]             #select data measurement with mean and standard variables
#Change variable names to something descriptive
varnames <- varnames[ind[3:length(ind)]-2]
varnames <- (gsub("[0-9]+ ","",varnames))  #get rid of numbers in front
varnames <- gsub("-mean\\(\\)","Mean",varnames) #get rid of dash and () in mean
varnames <- gsub("-std\\(\\)","Std",varnames)
varnames <- c("Activity","Subject",varnames)
names(data) <- varnames
data$Activity <- factor(data$Activity,level=1:6,labels=c("Walk","Walk_Up","Walk_Down","Sit","Stand","Lay"))
#Create the seconde data second required in the assignment
View(data_sum)
varnames
View(data)
#Create the seconde data second required in the assignment
data_sum <- aggregate(data[,3:dim(data)[2]],by=list(Acttivity=data$Activity,subject=data$Subject),mean)
#Write mean data to txt file
write.table(data_sum,file="data_sum.txt",row.name=FALSE)
View(data_sum)
View(data_sum)
x <- rnorm(1000)
y <- rchisqp(1000,1)
y <- rchisq(1000,1)
z <- x/sqrt(y)
hist(z)
x <- rnorm(1000)
x <- rnorm(100000)
y <- rchisq(100000,1)
z <- x/sqrt(y)
hist(z)
hist(z,breaks=100)
hist(z,breaks=1000)
z
head(z)
x <- rnorm(100000)
y <- rchisq(100000,4)
z <- x/sqrt(y/4)
hist(z,breaks=1000)
hist(z,breaks=100)
x <- rnorm(100000)
y <- rchisq(100000,10)
z <- x/sqrt(y/10)
hist(z,breaks=1000)
data(sleep)
sleep$extra
sleep
g1 <- sleep$textra[1:10]
g2 <- sleep$extra[11:20]
g1
g1 <- sleep$extra[1:10]
difference g2-g1
g2
g1
g2-1
g2-g1
difference <- g2-g1
mn <- mean(difference)
sd <- std(difference)
sd(difference)
s <- sd(difference)
n <- 10
mn + c(-1,1)*qt(.975,n-1)*s/sqrt(n)
t.test(difference)
t.test(difference)$conf.int
Y <- 4
data(wage)
1/2^5*5
1/2^5*6
install.packages("ISLR")
library(ISLR)
pairs(Auto)
attach(Auto)
hist(mpg)
Auto
autos <- Auto
str(autos)
autos$mpg
?lognorm
rlognorm
lognorma
?rlognorm
plnorm
plnorm(5,1)
plnorm(5,1)
plnorm(5,1)
plnorm(5,1)
rlnorm(5,1)
rlnorm(5,1)
rlnorm(5,1)
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
rlnorm(5,1)
rlnorm(5,1)
rlnorm(5,1)
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
exp(mean(log(rlnorm(5,1))))
mean(rlnrom(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
mean(rlnorm(5,1))
nosim <- 1000
mean(rlnorm(5,1))
mat <- matrix(rlnorm(5*nosim,1),5,1)
mat
?matrix
vec <- rlnorm(5*nosim,1)
mat <- matrix(data,nrow=nosim,ncol=5)
mat <- matrix(vec,nrow=nosim,ncol=5)
mean(mat)
nosim <- 10000
mat <- matrix(vec,nrow=nosim,ncol=5)
mean(mat)
vec <- rlnorm(5*nosim,1)
mat <- matrix(vec,nrow=nosim,ncol=5)
mean(mat)
?rlnorm
vec <- rlnorm(nosim,5,1)
mean(vec)
vec <- rlnorm(nosim,5,1)
mean(vec)
exp(5)
exp(5.5)
vec <- rlnorm(nosim,5,1)
mean(vec)
nosim <- 1000000
vec <- rlnorm(nosim,5,1)
mean(vec)
exp(mean(log(vec)))
dbeta(0.5,10,10)
dbeta(0.4,10,10)
dbeta(0.6,10,10)
library(UsingR)
install.packages("UsingR")
library(UsingR)
data(Galton)
par(mfrow=c(1,2))
hist(Galton)
hist(Galton$child,col="blue",breaks=100)
hist(Galton$parent,col="blue",breaks=100)
install.packages("manipulate")
library(manipulate)
myHist <- function(mu){hist(galton$child,col="blue",breaks=100)
lines(c(mu,mu),c(0,150),col="red",lwd=2)
mse <- mean((galton$child-mu)^2)
text(63,150,paste("mu=",mu))
text(63,140,paste("MSE=",round(mse,2)))}
manipulate(myHist(mu),mu=slider(62,74,step=.5))
par(mfrow=c(1,1))
manipulate(myHist(mu),mu=slider(62,74,step=.5))
plot(galton$parent,galton$child,pch=19,col="blue")
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x,y))
names(freqData) <- c("child","paretn","freq")
plot(
as.numeric(as.vector(freqData$parent))
as.numeric(as.vector(freqData$child)),
pch=21,col="black",bg="lightblue",
cex=.15*freqData$freq,
xlab="parent",
ylab="child"
)
abline(0,beta,lwd=3)
points(0,0,cex=2,pch=19)
mse <- mean((y-beta*x)^2)
title(paste("beta=",beta,"mse =",round(mse,3)))
}
manipulate(myPlot(beta,beta=slider(0.8,1.2,step=.02)))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x,y))
names(freqData) <- c("child","parent","freq")
plot(
as.numeric(as.vector(freqData$parent))
as.numeric(as.vector(freqData$child)),
pch=21,col="black",bg="lightblue",
cex=.15*freqData$freq,
xlab="parent",
ylab="child"
)
abline(0,beta,lwd=3)
points(0,0,cex=2,pch=19)
mse <- mean((y-beta*x)^2)
title(paste("beta=",beta,"mse =",round(mse,3)))
}
manipulate(myPlot(beta,beta=slider(0.8,1.2,step=.02)))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x,y))
names(freqData) <- c("child","parent","freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch=21,col="black",bg="lightblue",
cex=.15*freqData$freq,
xlab="parent",
ylab="child"
)
abline(0,beta,lwd=3)
points(0,0,cex=2,pch=19)
mse <- mean((y-beta*x)^2)
title(paste("beta=",beta,"mse =",round(mse,3)))
}
manipulate(myPlot(beta,beta=slider(0.8,1.2,step=.02)))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x,y))
names(freqData) <- c("child","parent","freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch=21,col="black",bg="lightblue",
cex=.15*freqData$freq,
xlab="parent",
ylab="child"
)
abline(0,beta,lwd=3)
points(0,0,cex=2,pch=19)
mse <- mean((y-beta*x)^2)
title(paste("beta=",beta,"mse =",round(mse,3)))
}
manipulate(myPlot(beta),beta=slider(0.8,1.2,step=.02)))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x,y))
names(freqData) <- c("child","parent","freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch=21,col="black",bg="lightblue",
cex=.15*freqData$freq,
xlab="parent",
ylab="child"
)
abline(0,beta,lwd=3)
points(0,0,cex=2,pch=19)
mse <- mean((y-beta*x)^2)
title(paste("beta=",beta,"mse =",round(mse,3)))
}
manipulate(myPlot(beta),beta=slider(0.8,1.2,step=.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x,y))
names(freqData) <- c("child","parent","freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch=21,col="black",bg="lightblue",
cex=.15*freqData$freq,
xlab="parent",
ylab="child"
)
abline(0,beta,lwd=3)
points(0,0,cex=2,pch=19)
mse <- mean((y-beta*x)^2)
title(paste("beta=",beta,"mse =",round(mse,3)))
}
manipulate(myPlot(beta),beta=slider(0.6,1.2,step=.02))
x <- c(0.18,0.18,-1.54,0.42,0.42,0.42,0.95)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(x~y -1 )
lm(y~x -1 )
data(mtcars)
fit <- lm(mpg~weight,data=mtcars)
head(mtcars)
fit <- lm(mpg~wt,data=mtcars)
fit
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
(x-mean(x))/sd(x)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y~x)
x
y
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
fit <- lm(y~x)
fit
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModelling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
diagnosis
predictors
head(predictors)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
training
data(concrete)
set.seed(975)
inTrain <- createDataPartition(mixtures$CompressiveStrenght,p=0.75)[[1]]
inTrain <- createDataPartition(mixtures$CompressiveStrength,p=0.75)[[1]]
training <- mixtures[inTrain,]
testing <- mixtures[-inTrain,]
install.packages("Hmisc")
install.packages("Hmisc")
setwd("C:/Users/localusr/Desktop/Stats/08 - ML/Practiacal-Machine-Learning")
setInternet2(use=TRUE)
urll <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(urll,destfile="train.csv")
urll <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(urll,destfile="test.csv")
training <- read.csv("train.csv",na.string=c("","NA"))
valid <- read.csv("test.csv",na.string=c("","NA"))
library(caret)
inTrain <- createDataPartition(y=training$classe,p=0.6,list=FALSE)
testing <- training[-inTrain,]
training <- training[inTrain,]
nas <- colMeans(is.na(training))
training <- training[,nas < 0.5]
training <- training[,-5:-1]
cn <- colnames(training)
testing <- testing[,cn]
valid <- valid[,cn[-length(cn)]]
sum(is.na(training))
sum(is.na(testing))
inTrain2 <- createDataPartition(y=training$classe,p=0.8,list=FALSE)
train2 <- training[inTrain2,]
test2 <- training[-inTrain2,]
lmfit <- train(classe ~ ., data=train2, method="lda")
confusionMatrix(test2$classe,predict(lmfit,test2))
inTrain2 <- createDataPartition(y=training$classe,p=0.8,list=FALSE)
train2 <- training[inTrain2,]
test2 <- training[-inTrain2,]
forestfit <- train(classe ~ ., data=train2, method="rf")
confusionMatrix(test2$classe,predict(forestfit,test2))
predict(forestfit,valid)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
ans <- predict(forestfit,valid)
pml_write_files(ans)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain <- createDataPartition(segmentationOriginal$Case,p=0.8,list=FALSE)
train <- segmentationOriginal[inTrain]
training <- segmentationOriginal[inTrain]
fit <- train(Case ~ ., data=training, method="rpart")
fit <- train(Case ~ ., method="rpart", data=training)
training
fit <- train(Case ~ ., method="rpart", data=training)
library(caret)
fit <- train(Case ~ ., method="rpart", data=training)
